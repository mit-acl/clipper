{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Association of Noisy Stanford Bunny with Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from scipy.spatial.transform import Rotation\n",
    "import clipper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(pcfile, m, n1, n2o, outrat, sigma, T_21):\n",
    "    \"\"\"Generate Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    pcd = o3d.io.read_point_cloud(pcfile)\n",
    "\n",
    "    n2 = n1 + n2o # number of points in view 2\n",
    "    noa = round(m * outrat) # number of outlier associations\n",
    "    nia = m - noa # number of inlier associations\n",
    "\n",
    "    if nia > n1:\n",
    "        raise ValueError(\"Cannot have more inlier associations \"\n",
    "                         \"than there are model points. Increase\"\n",
    "                         \"the number of points to sample from the\"\n",
    "                         \"original point cloud model.\")\n",
    "\n",
    "    # radius of outlier sphere\n",
    "    R = 1\n",
    "\n",
    "    # Downsample from the original point cloud, sample randomly\n",
    "    I = np.random.choice(len(pcd.points), n1, replace=False)\n",
    "    D1 = np.asarray(pcd.points)[I,:].T\n",
    "\n",
    "    # Rotate into view 2 using ground truth transformation\n",
    "    D2 = T_21[0:3,0:3] @ D1 + T_21[0:3,3].reshape(-1,1)\n",
    "\n",
    "    # Add noise uniformly sampled from a sigma cube around the true point\n",
    "    eta = np.random.uniform(low=-sigma/2., high=sigma/2., size=D2.shape)\n",
    "\n",
    "    # Add noise to view 2\n",
    "    D2 += eta\n",
    "\n",
    "    def randsphere(m,n,r):\n",
    "        from scipy.special import gammainc\n",
    "        X = np.random.randn(m, n)\n",
    "        s2 = np.sum(X**2, axis=1)\n",
    "        X = X * np.tile((r*(gammainc(n/2,s2/2)**(1/n)) / np.sqrt(s2)).reshape(-1,1),(1,n))\n",
    "        return X\n",
    "\n",
    "    # Add outliers to view 2\n",
    "    O2 = randsphere(n2o,3,R).T + D2.mean(axis=1).reshape(-1,1)\n",
    "    D2 = np.hstack((D2,O2))\n",
    "\n",
    "    # Correct associations to draw from\n",
    "    Agood = np.tile(np.arange(n1).reshape(-1,1),(1,2))\n",
    "\n",
    "    # Incorrect association to draw from\n",
    "    Abad = np.zeros((n1*n2 - n1, 2))\n",
    "    itr = 0\n",
    "    for i in range(n1):\n",
    "        for j in range(n2):\n",
    "            if i == j:\n",
    "                continue\n",
    "            Abad[itr,:] = [i, j]\n",
    "            itr += 1\n",
    "\n",
    "    # Sample good and bad associations to satisfy total\n",
    "    # num of associations with the requested outlier ratio\n",
    "    IAgood = np.random.choice(Agood.shape[0], nia, replace=False)\n",
    "    IAbad = np.random.choice(Abad.shape[0], noa, replace=False)\n",
    "    A = np.concatenate((Agood[IAgood,:],Abad[IAbad,:]))\n",
    "\n",
    "    # Ground truth associations\n",
    "    Agt = Agood[IAgood,:]\n",
    "    \n",
    "    return (D1, D2, Agt, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 1000      # total number of associations in problem\n",
    "n1 = 1000     # number of points used on model (i.e., seen in view 1)\n",
    "n2o = 250     # number of outliers in data (i.e., seen in view 2)\n",
    "outrat = 0.95 # outlier ratio of initial association set\n",
    "sigma = 0.02  # uniform noise [m] range\n",
    "\n",
    "# generate random (R,t)\n",
    "T_21 = np.eye(4)\n",
    "T_21[0:3,0:3] = Rotation.random().as_matrix()\n",
    "T_21[0:3,3] = np.random.uniform(low=-5, high=5, size=(3,))\n",
    "\n",
    "pcfile = '../data/bun10k.ply'\n",
    "\n",
    "D1, D2, Agt, A = generate_dataset(pcfile, m, n1, n2o, outrat, sigma, T_21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affinity matrix creation took 0.066 seconds\n",
      "CLIPPER selected 41 inliers from 1000 putative associations (precision 1.00, recall 0.82) in 0.085 s\n"
     ]
    }
   ],
   "source": [
    "params = clipper.Params()\n",
    "params.beta = 0.25 # this was the value in the original version of the repo\n",
    "iparams = clipper.invariants.EuclideanDistanceParams()\n",
    "iparams.sigma = 0.015\n",
    "iparams.epsilon = 0.02\n",
    "invariant = clipper.invariants.EuclideanDistance(iparams)\n",
    "\n",
    "t0 = time.time()\n",
    "M, C = clipper.score_pairwise_consistency(invariant, D1, D2, A)\n",
    "t1 = time.time()\n",
    "print(f\"Affinity matrix creation took {t1-t0:.3f} seconds\")\n",
    "t0 = time.time()\n",
    "soln = clipper.find_dense_cluster(M, C, params)\n",
    "t1 = time.time()\n",
    "Ain = clipper.select_inlier_associations(soln, A)\n",
    "dense_duration = t1 - t0\n",
    "\n",
    "p = np.isin(Ain, Agt)[:,0].sum() / Ain.shape[0]\n",
    "r = np.isin(Ain, Agt)[:,0].sum() / Agt.shape[0]\n",
    "print(f\"CLIPPER selected {Ain.shape[0]} inliers from {A.shape[0]} \"\n",
    "      f\"putative associations (precision {p:.2f}, recall {r:.2f}) in {t1-t0:.3f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PointCloud with 1250 points."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = o3d.geometry.PointCloud()\n",
    "model.points = o3d.utility.Vector3dVector(D1.T)\n",
    "model.paint_uniform_color(np.array([0,0,1.]))\n",
    "data = o3d.geometry.PointCloud()\n",
    "data.points = o3d.utility.Vector3dVector(D2.T)\n",
    "data.paint_uniform_color(np.array([1.,0,0]))\n",
    "\n",
    "# corr = o3d.geometry.LineSet.create_from_point_cloud_correspondences(model, data, Ain)\n",
    "# o3d.visualization.draw_geometries([model, data, corr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2p = o3d.pipelines.registration.TransformationEstimationPointToPoint()\n",
    "That_21 = p2p.compute_transformation(model, data, o3d.utility.Vector2iVector(Ain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_err(T, That):\n",
    "    Terr = np.linalg.inv(T) @ That\n",
    "    rerr = abs(np.arccos(min(max(((Terr[0:3,0:3]).trace() - 1) / 2, -1.0), 1.0)))\n",
    "    terr = np.linalg.norm(Terr[0:3,3])\n",
    "    return (rerr, terr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0063437045150311604, 0.0011663986322407618)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_err(T_21, That_21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_registration_result(source, target, transformation):\n",
    "    import copy\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_registration_result(model, data, That_21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploiting Sparsity in Affinity matrix\n",
    "\n",
    "we run the above with sparsity-aware version of clipper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affinity matrix creation took 0.063 seconds\n",
      "sparse-aware CLIPPER selected 40 inliers from 1000 putative associations (precision 1.00, recall 0.80) in 0.012 s\n",
      "Speed-up: 6.964860907759883\n"
     ]
    }
   ],
   "source": [
    "params = clipper.Params()\n",
    "iparams = clipper.invariants.EuclideanDistanceParams()\n",
    "iparams.sigma = 0.015\n",
    "iparams.epsilon = 0.02\n",
    "invariant = clipper.invariants.EuclideanDistance(iparams)\n",
    "\n",
    "t0 = time.time()\n",
    "M, C = clipper.score_sparse_pairwise_consistency(invariant, D1, D2, A)\n",
    "t1 = time.time()\n",
    "print(f\"Affinity matrix creation took {t1-t0:.3f} seconds\")\n",
    "t0 = time.time()\n",
    "soln = clipper.find_dense_cluster_of_sparse_graph(M, C, params)\n",
    "t1 = time.time()\n",
    "Ain = clipper.select_inlier_associations(soln, A)\n",
    "sparse_duration = t1 - t0\n",
    "\n",
    "p = np.isin(Ain, Agt)[:,0].sum() / Ain.shape[0]\n",
    "r = np.isin(Ain, Agt)[:,0].sum() / Agt.shape[0]\n",
    "print(f\"sparse-aware CLIPPER selected {Ain.shape[0]} inliers from {A.shape[0]} \"\n",
    "      f\"putative associations (precision {p:.2f}, recall {r:.2f}) in {t1-t0:.3f} s\")\n",
    "\n",
    "print(f\"Speed-up: {dense_duration / sparse_duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2p = o3d.pipelines.registration.TransformationEstimationPointToPoint()\n",
    "That_21 = p2p.compute_transformation(model, data, o3d.utility.Vector2iVector(Ain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.006657570406907475, 0.0011222630927085323)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_err(T_21, That_21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_registration_result(model, data, That_21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Invariant Function\n",
    "\n",
    "For most cases, we recommend using the provided invariants written in C++ for computational efficiency. In particular, for C++ invariant implementations, we use `OpenMP` to parallelize the computation of the affinity matrix.\n",
    "\n",
    "However, for quick tests and prototyping it can be convenient to test invariants using Python. In this case, you can extend the C++ `clipper.invariants.PairwiseInvariant` class in Python. Note that this method disables the `OpenMP` parallelization is so will be many times slower than a C++ implementation. On average, for the following Python example invariant, the `score_pairwise_consistency` method takes 6 seconds for 1000 initial associations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom(clipper.invariants.PairwiseInvariant):\n",
    "    def __init__(self, σ=0.06, ϵ=0.01):\n",
    "        clipper.invariants.PairwiseInvariant.__init__(self)\n",
    "        self.σ = σ\n",
    "        self.ϵ = ϵ\n",
    "        \n",
    "    def __call__(self, ai, aj, bi, bj):\n",
    "        l1 = np.linalg.norm(ai - aj)\n",
    "        l2 = np.linalg.norm(bi - bj)\n",
    "        \n",
    "        c = np.abs(l1 - l2)\n",
    "        \n",
    "        return np.exp(-0.5*c**2/self.σ**2) if c < self.ϵ else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Custom(σ=0.015, ϵ=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = clipper.Params()\n",
    "\n",
    "t0 = time.time()\n",
    "M, C = clipper.score_pairwise_consistency(c, D1, D2, A)\n",
    "t1 = time.time()\n",
    "print(f\"Affinity matrix creation took {t1-t0:.3f} seconds\")\n",
    "t0 = time.time()\n",
    "soln = clipper.find_dense_cluster(M, C, params)\n",
    "t1 = time.time()\n",
    "Ain = clipper.select_inlier_associations(soln, A)\n",
    "\n",
    "p = np.isin(Ain, Agt)[:,0].sum() / Ain.shape[0]\n",
    "r = np.isin(Ain, Agt)[:,0].sum() / Agt.shape[0]\n",
    "print(f\"CLIPPER selected {Ain.shape[0]} inliers from {A.shape[0]} \"\n",
    "      f\"putative associations (precision {p:.2f}, recall {r:.2f}) in {t1-t0:.3f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pure Python Implementation of Pairwise Consistency Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k2ij(k, n):\n",
    "    k += 1\n",
    "    \n",
    "    l = n * (n-1) / 2 - k\n",
    "    o = np.floor( (np.sqrt(1 + 8*l) - 1) / 2. )\n",
    "    p = l - o * (o + 1) / 2\n",
    "    i = n - (o + 1)\n",
    "    j = n - p\n",
    "    \n",
    "    return int(i-1), int(j-1)\n",
    "\n",
    "def score_pairwise_consistency(invariant, D1, D2, A):\n",
    "    if A is None:\n",
    "        A = clipper.invariants.create_all_to_all(D1.shape[1], D2.shape[1])\n",
    "        \n",
    "    m = A.shape[0]\n",
    "    \n",
    "    M = np.eye(m)\n",
    "    C = np.ones((m,m))\n",
    "    \n",
    "    for k in range(int(m*(m-1)/2)):\n",
    "        i, j = k2ij(k, m)\n",
    "        \n",
    "        if A[i,0] == A[j,0] or A[i,1] == A[j,1]:\n",
    "            C[i,j] = C[j,i] = 0\n",
    "            continue\n",
    "            \n",
    "        d1i = D1[:,A[i,0]]\n",
    "        d1j = D1[:,A[j,0]]\n",
    "        \n",
    "        d2i = D2[:,A[i,1]]\n",
    "        d2j = D2[:,A[j,1]]\n",
    "        \n",
    "        scr = invariant(d1i,d1j,d2i,d2j)\n",
    "        if scr > 0:\n",
    "            M[i,j] = M[j,i] = scr\n",
    "        else:\n",
    "            C[i,j] = C[j,i] = 0\n",
    "    \n",
    "    return M, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "_, _ = score_pairwise_consistency(c, D1, D2, A.astype('int'))\n",
    "t1 = time.time()\n",
    "print(f\"Affinity matrix creation took {t1-t0:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
